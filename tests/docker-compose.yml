version: '3.8'

services:

  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.3
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=elasticelastic123
      - xpack.security.http.ssl.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elastic-data:/usr/share/elasticsearch/data
    networks:
      - pipeline-net

  kibana:
    image: docker.elastic.co/kibana/kibana:8.17.3
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_SERVICEACCOUNTTOKEN=AAEAAWVsYXN0aWMva2liYW5hL2tpYmFuYS10b2tlbjpRRWdXS1VZRFExaUhoaDM3U2QxUG1n

    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - pipeline-net

  init-index:
    build:
      context: ./init
    depends_on:
      - elasticsearch
    networks:
      - pipeline-net

  kibana-init:
    build:
      context: ./kibana-init
    depends_on:
      - kibana
    networks:
      - pipeline-net

  nifi:
    image: apache/nifi:2.3.0
    container_name: nifi
    environment:
      - NIFI_WEB_HTTPS_PORT=8443
      - SINGLE_USER_CREDENTIALS_USERNAME=admin
      - SINGLE_USER_CREDENTIALS_PASSWORD=adminadmin123
      - NIFI_SECURITY_USER_AUTHORIZER=single-user-authorizer
      - NIFI_SECURITY_USER_LOGIN_IDENTITY_PROVIDER=single-user-provider
    ports:
      - "8443:8443"
    volumes:
      - nifi-conf:/opt/nifi/nifi-current/conf
      - nifi-state:/opt/nifi/nifi-current/state
      - ./data/staging:/data/staging
      - ./data/landing:/data/landing
      - ./data/processed:/data/processed
      - ./data/archive:/data/archive
      - ./data/error:/data/error
#    depends_on:
#      - nifi-registry
    networks:
      - pipeline-net


#  nifi-registry:
#    image: apache/nifi-registry:1.26.0
#    container_name: nifi-registry
#    environment:
#      - NIFI_REGISTRY_WEB_HTTP_PORT=18080
#    ports:
#      - "18080:18080"
#    volumes:
#      - ./nifi-flows:/opt/nifi-registry/flow_storage
#    networks:
#      - pipeline-net

  # Flask app service (Pyspark Client/Driver)
  spark-service: # Keeping your original service name
    build:
      context: ./spark_service # Path to your Flask app's Dockerfile and source
    container_name: spark-service # Keeping your original container name
    ports:
      - "5001:5001"  # Flask application port
      - "4041:4041"  # Spark Application UI port (driver UI)
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077 # Tells PySpark where the master is
    deploy:
      resources:
        limits:
          cpus: '0.75' # Max CPU for the Flask app + Spark Driver
          memory: 1.5G # Max RAM for the Flask app + Spark Driver
        reservations:
          cpus: '0.3'  # Guaranteed CPU
          memory: 1G   # Guaranteed RAM
    volumes:
      # The driver will write the final Parquet files directly to this path.
      # This path is mapped to the host's ./data/processed directory.
      - ./data/processed:/host_data_processed

      # If you had specific logs or other data you wanted to persist from the Flask app:
      # - ./spark_service_logs:/app/logs # Example if your app logs to /app/logs
    networks:
      - pipeline-net

  spark-master:
    image: bitnami/spark:3.5.0
    container_name: spark-master
    ports:
      - "8081:8080"  # Spark Master Web UI (using 8081 on host to avoid conflict if something else uses 8080)
      - "7077:7077"  # Spark Master communication port
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no # For simplicity in local dev
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M
    networks:
      - pipeline-net # Your defined network

  spark-worker-1:
    image: bitnami/spark:3.5.0
    container_name: spark-worker-1
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077 # Connect to the master service
      - SPARK_WORKER_MEMORY=1G    # Memory this worker offers to Spark applications
      - SPARK_WORKER_CORES=1      # Cores this worker offers
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_WORKER_WEBUI_PORT=8082 # Different UI port for this worker on its container
    ports: # Optional: if you want to access individual worker UIs
      - "8082:8082"
    deploy:
      resources:
        limits:
          cpus: '0.75' # Max CPU for the worker container itself
          memory: 1.5G # Slightly more than SPARK_WORKER_MEMORY for overhead
        reservations:
          cpus: '0.3'
          memory: 1G
    networks:
      - pipeline-net
    volumes:
      - spark_work_1:/opt/bitnami/spark/work # For Spark's temporary data
      - shared_processed_data:/spark_output_internal # Internal path for Spark output

  spark-worker-2:
    image: bitnami/spark:3.5.0
    container_name: spark-worker-2
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_WORKER_WEBUI_PORT=8083 # Different UI port for this worker
    ports:
      - "8083:8083"
    deploy:
      resources:
        limits:
          cpus: '0.75'
          memory: 1.5G
        reservations:
          cpus: '0.3'
          memory: 1G
    networks:
      - pipeline-net
    volumes:
      - spark_work_2:/opt/bitnami/spark/work
      - shared_processed_data:/spark_output_internal # Internal path for Spark output

volumes:
  elastic-data:
  kibana-data:
  nifi-conf:
  nifi-state:
  spark_work_1:
  spark_work_2:
  shared_processed_data:
 
networks:
  pipeline-net:
    driver: bridge
