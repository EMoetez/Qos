version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.17.3
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=true
      - ELASTIC_PASSWORD=elasticelastic123
      - xpack.security.http.ssl.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elastic-data:/usr/share/elasticsearch/data
    networks:
      - pipeline-net

  kibana:
    image: docker.elastic.co/kibana/kibana:8.17.3
    container_name: kibana
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_SERVICEACCOUNTTOKEN=${KIBANA_SA_TOKEN}
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    networks:
      - pipeline-net

  init-index:
    build:
      context: ./init
    depends_on:
      - elasticsearch
    networks:
      - pipeline-net

  kibana-init:
    build:
      context: ./kibana-init
    depends_on:
      - kibana
    networks:
      - pipeline-net

  nifi:
    build:
      context: ./nifi-init
      args:
        NIFI_VERSION: 2.3.0 
    container_name: nifi
    ports:
      - "8443:8443" 
    environment:
      - NIFI_WEB_HTTPS_PORT=8443
      - SINGLE_USER_CREDENTIALS_USERNAME=admin
      - SINGLE_USER_CREDENTIALS_PASSWORD=adminadmin123
      - NIFI_SECURITY_USER_AUTHORIZER=single-user-authorizer
      - NIFI_SECURITY_USER_LOGIN_IDENTITY_PROVIDER=single-user-provider
      - NIFI_SENSITIVE_PROPS_KEY=HMu+8MgUunhfS1hRUcCUeM1x0PspQdX1
    volumes:
      - nifi_conf:/opt/nifi/nifi-current/conf
      - nifi_database_repository:/opt/nifi/nifi-current/database_repository
      - nifi_flowfile_repository:/opt/nifi/nifi-current/flowfile_repository
      - nifi_content_repository:/opt/nifi/nifi-current/content_repository
      - nifi_provenance_repository:/opt/nifi/nifi-current/provenance_repository
      - nifi_state:/opt/nifi/nifi-current/state
      - ./data/staging:/data/staging
      - ./data/landing:/data/landing
      - ./data/processed:/data/processed
      - ./data/archive:/data/archive
      - ./data/error:/data/error
    #depends_on: # Assuming you want NiFi to depend on NiFi Registry if it's active
      #- nifi-registry
    networks:
      - pipeline-net

#  nifi-registry:
#    image: apache/nifi-registry:1.26.0
#    container_name: nifi-registry
#    environment:
#      - NIFI_REGISTRY_WEB_HTTP_PORT=18080
#    ports:
#      - "18080:18080"
#    volumes:
#      - ./nifi-flows:/opt/nifi-registry/flow_storage
#    networks:
#      - pipeline-net

  # Flask app service (Pyspark Client/Driver)
  spark-service: # Keeping your original service name
    build:
      context: ./spark_service # Path to your Flask app's Dockerfile and source
    container_name: spark-service # Keeping your original container name
    ports:
      - "5001:5001"  # Flask application port
      - "4041:4041"  # Spark Application UI port (driver UI)
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER_URL=spark://spark-master:7077 # Tells PySpark where the master is
    deploy:
      resources:
        limits:
          cpus: '0.75' # Max CPU for the Flask app + Spark Driver
          memory: 1.5G # Max RAM for the Flask app + Spark Driver
        reservations:
          cpus: '0.3'  # Guaranteed CPU
          memory: 1G   # Guaranteed RAM
    volumes:
      # The driver will write the final Parquet files directly to this path.
      # This path is mapped to the host's ./data/processed directory.
      - ./data/processed:/host_data_processed:z
      # If you had specific logs or other data you wanted to persist from the Flask app:
      # - ./spark_service_logs:/app/logs # Example if your app logs to /app/logs
    networks:
      - pipeline-net

  spark-master:
    image: bitnami/spark:3.5.0
    container_name: spark-master
    ports:
      - "8081:8080"  # Spark Master Web UI (using 8081 on host to avoid conflict if something else uses 8080)
      - "7077:7077"  # Spark Master communication port
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no # For simplicity in local dev
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 1G
        reservations:
          cpus: '0.25'
          memory: 512M
    networks:
      - pipeline-net # Your defined network

  spark-worker-1:
    image: bitnami/spark:3.5.0
    container_name: spark-worker-1
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077 # Connect to the master service
      - SPARK_WORKER_MEMORY=1G    # Memory this worker offers to Spark applications
      - SPARK_WORKER_CORES=1      # Cores this worker offers
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_WORKER_WEBUI_PORT=8082 # Different UI port for this worker on its container
    ports: # Optional: if you want to access individual worker UIs
      - "8082:8082"
    deploy:
      resources:
        limits:
          cpus: '0.75' # Max CPU for the worker container itself
          memory: 1.5G # Slightly more than SPARK_WORKER_MEMORY for overhead
        reservations:
          cpus: '0.3'
          memory: 1G
    networks:
      - pipeline-net
    volumes:
      - spark_work_1:/opt/bitnami/spark/work # For Spark's temporary data
      # - shared_processed_data:/spark_output_internal # REMOVED: Not needed if driver handles final output

  spark-worker-2:
    image: bitnami/spark:3.5.0
    container_name: spark-worker-2
    depends_on:
      - spark-master
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_WORKER_WEBUI_PORT=8083 # Different UI port for this worker
    ports:
      - "8083:8083"
    deploy:
      resources:
        limits:
          cpus: '0.75'
          memory: 1.5G
        reservations:
          cpus: '0.3'
          memory: 1G
    networks:
      - pipeline-net
    volumes:
      - spark_work_2:/opt/bitnami/spark/work # For Spark's temporary data
      # - shared_processed_data:/spark_output_internal # REMOVED: Not needed if driver handles final output

volumes:
  elastic-data:
  kibana-data:
  spark_work_1:
  spark_work_2:
  nifi_conf:
  nifi_database_repository:
  nifi_flowfile_repository:
  nifi_content_repository:
  nifi_provenance_repository:
  nifi_state:
  
  # shared_processed_data: # REMOVED: No longer used by Spark services for output

networks:
  pipeline-net:
    driver: bridge